---
title: 'Lecture 2 code'
author: "Mark Wilber"
date: "`r Sys.Date()`"
output: html_document
---


```{r}
# Relative likelihood
library(ggplot2)

# This example is on slide 5/6 of week2_chapter2.pdf slides. 

# Plot likelihood for different probabilities of success
prob_success = seq(0.001, 0.999, len=100)
num_success = 6
num_fail = 2
rel_likelihood = prob_success^num_success * (1 - prob_success)^num_fail
ggplot() + geom_line(aes(x=prob_success, 
						 y=rel_likelihood)) +
		 xlab("Prob. successs") + ylab("Relative likelihood") + theme_classic()

# ggsave("relative_likelihood.pdf", width=5, height=3)
```

```{r}
# Absolute likelihood

likelihood = choose(8, 6)*prob_success^num_success * (1 - prob_success)^num_fail
ggplot() + geom_line(aes(x=prob_success, 
						 y=likelihood)) +
		 xlab("Prob. successs") + ylab("Likelihood") + theme_classic()

# ggsave("likelihood.pdf", width=5, height=3)
```

```{r}
# The binomial distribution in R

# Calculate the probability of 6 success and 2 failures given p = 0.25
dbinom(6, p=0.25, size=8) #Arguments dbinom(successes, p= prob_of_success, size = num_of_trials)

# Compare to our by hand calculation...same answer
choose(8, 6)*(0.25)^6 * (1 - 0.25)^2

# Simulate data with a binomial distribution.
# Repeat the the experiment with northern harriers 10000 times (8 trials each time)
# Assume the probability of success is 0.25
# What proportion of times will harriers succeed six or more times?
data_simulation = rbinom(10000, p=0.25, size=8) # rbinom(num_of_samples, p=prob_of_success, size = num_of_trials)
    #the prefix "r" in rbinom is "random"; sampling the binomial distribution 
head(data_simulation)

hist(data_simulation) # Histogram of the simulations sampling the binomial distribution 

print(mean(data_simulation >= 6))
# 0.0038
```

```{r}
# Prior distributions

# Flat prior
pvals = seq(0, 1, len=100)
prior1 = dbeta(pvals, 1, 1)
ggplot() + geom_line(aes(x=pvals, y=prior1)) + 
		   xlab("Probability of success") + ylab("Prior plausibility") + theme_classic()

# ggsave("prior1.pdf", width=5, height=3)

# Slightly informative prior
mu = 0.5
phi = 3
a = mu*phi
b = (1 - mu)*phi
prior2 = dbeta(pvals, a, b)
ggplot() + geom_line(aes(x=pvals, y=prior2)) + 
		   xlab("Probability of success") + ylab("Prior plausibility") + theme_classic()

# ggsave("prior2.pdf", width=5, height=3)

# Very informative prior
    # This is a parameterization of the beta distribution by its mean and precision (1/(var)). Refer to "Alternative Parameterizations --> "Mean and sample size" of https://en.wikipedia.org/wiki/Beta_distribution for info on how he derived this parameterization. 
mu = 0.25 # mean
phi = 30 # precision; 1/(var)
a = mu*phi 
b = (1 - mu)*phi
prior2 = dbeta(pvals, a, b)
ggplot() + geom_line(aes(x=pvals, y=prior2)) + 
		   xlab("Probability of success") + ylab("Prior plausibility") + theme_classic()

# ggsave("prior3.pdf", width=5, height=3)

# Uninformative prior
mu = 0.5
phi = 0.2
a = mu*phi
b = (1 - mu)*phi
prior2 = dbeta(pvals, a, b)
ggplot() + geom_line(aes(x=pvals, y=prior2)) + 
		   xlab("Probability of success") + ylab("Prior plausibility") + theme_classic()

# ggsave("prior4.pdf", width=5, height=3)
```

```{r}
pvals = seq(0, 1, len=100)
posterior = dbeta(pvals, 1 + 6, 1 + 2)
ggplot() + geom_line(aes(x=pvals, y=posterior)) + 
		   xlab("Probability of success") + ylab("Posterior distribution") + theme_classic()

# ggsave("posterior.pdf", width=5, height=3)
```

```{r}
## Beta distribution interlude

#  A uniform distribution
pvals = seq(0, 1, len=100)
shape1 = 1
shape2 = 1
uniform = dbeta(pvals, shape1, shape2)

ggplot() + geom_line(aes(x=pvals, y=uniform)) +
            xlab("p") + ylab("Probability density")
# ggsave("prior_example1.pdf", width=4, height=3)

#  A unimodal distribution
pvals = seq(0, 1, len=100)
mu = 0.75 # Mean value
phi = 8 # Precision (higher value = less spread)
shape1 = mu*phi
shape2 = (1 - mu)*phi
unimodal = dbeta(pvals, shape1, shape2)
plot(pvals, unimodal, type="l", xlab="p", 
   ylab="Probability density")

ggplot() + geom_line(aes(x=pvals, y=unimodal)) +
            xlab("p") + ylab("Probability density")
# ggsave("prior_example2.pdf", width=4, height=3)
```

```{r}
## Grid approximation

# 1. Define grid
p_grid = seq(0, 1, len=100)
dp = p_grid[2] - p_grid[1]

# 2. Compute prior
prior = dunif(p_grid, 0, 1)

# 3. Compute likelihood
likelihood = dbinom(6, size=8, prob=p_grid)

# 4. Compute unnormalized posterior
unnorm_posterior = prior * likelihood

# 5. Normalize posterior to "integrate" to one
posterior = unnorm_posterior / sum(unnorm_posterior)
posterior

mean_p = sum(posterior * p_grid)
mode_p = p_grid[which.max(posterior)]

# Compare posterior and prior
p1 = ggplot() + geom_line(aes(x=p_grid, y=posterior, linetype="Posterior")) + 
		   geom_line(aes(x=p_grid, y=prior*dp, linetype="Prior")) +
		   ylab("Probability") + xlab("Prob. successful attack") +
		   theme_classic()

# ggsave("inference1.pdf", width=4, height=3)

p1 + geom_vline(aes(xintercept=mean_p, color="mean")) + 
	 geom_vline(aes(xintercept=mode_p, color="mode"))

# ggsave("inference1a.pdf", width=4, height=3)
```

```{r}
## Grid approximation

# 1. Define grid
p_grid = seq(0.001, 0.999, len=100)
dp = p_grid[2] - p_grid[1]

# 2. Compute prior
mu = 0.5
phi = 0.2
a = mu*phi
b = (1 - mu)*phi
prior = dbeta(p_grid, a, b)

# plot(prior)

# 3. Compute likelihood
likelihood = dbinom(6, size=8, prob=p_grid)

# 4. Compute unnormalized posterior
unnorm_posterior = prior * likelihood

# 5. Normalize posterior to "integrate" to one
posterior = unnorm_posterior / sum(unnorm_posterior)

mean_p = sum(posterior * p_grid)
mode_p = p_grid[which.max(posterior)]

# Compare posterior and prior
p1 = ggplot() + geom_line(aes(x=p_grid, y=posterior, linetype="Posterior")) + 
		   geom_line(aes(x=p_grid, y=prior*dp, linetype="Prior")) +
		   ylab("Probability") + xlab("Prob. successful attack") +
		   theme_classic()
# ggsave("inference2.pdf", width=4, height=3)

p1 + geom_vline(aes(xintercept=mean_p, color="mean")) + 
	 geom_vline(aes(xintercept=mode_p, color="mode"))

# ggsave("inference2a.pdf", width=4, height=3)
```

```{r}
## Quadratic approximation: Approach 1

library(rethinking)
library(ggplot2)

harrier = quap( # quap: quadratic approximation 
	alist(
		Y ~ dbinom(Y + F, p), # Likelihood (number of successful attacks)
		                      # Y: successes; F: failures (total of 8 trials)
		p ~ dunif(0, 1) # Prior 
	),
	data=list(Y = 6, F = 2)) # takes either a data frame or a list
                           # contains the things you want to reference in "alist" 


# harrier  #provides some information about what quap produces 


# "precis" function

# precis(harrier)
mean_est = precis(harrier)$mean[1] 
sd_est = precis(harrier)$sd[1]

# 1. Define grid
p_grid = seq(0, 1, len=100)
dp = p_grid[2] - p_grid[1]
prior = dunif(p_grid, 0, 1)
likelihood = dbinom(6, size=8, prob=p_grid)
unnorm_posterior = prior * likelihood
grid_posterior = unnorm_posterior / sum(unnorm_posterior)

quad_posterior = dnorm(p_grid, mean=mean_est, sd=sd_est)

ggplot() + geom_line(aes(x=p_grid, y=grid_posterior, color="Grid posterior")) +
		   geom_line(aes(x=p_grid, y=quad_posterior*dp, color="Quadratic posterior")) +
		   xlab("Prob. successful attack") + ylab("Probability") + theme_classic()

# ggsave("compare_posteriors.pdf", width=5, height=3)
```


```{r}
## Quadratic approximation: Practice Problem

library(rethinking)
library(ggplot2)

hawk = quap( # quap: quadratic approximation 
	alist(
		Y ~ dbinom(Y + F, p), # Likelihood (number of successful attacks)
		                      # Y: successes; F: failures (total of 8) trials)
		p ~ dbeta(1.1, 5) # Prior 
	),
	data=list(Y = 0, F = 8)) # takes either a data frame or a list
                           # contains the things you want to reference in "alist" 


# hawk  #provides some information about what quap produces 


# "precis" function

# precis(hawk)
mean_est = precis(hawk)$mean[1] 
sd_est = precis(hawk)$sd[1]

# 1. Define grid
p_grid = seq(0, 1, len=100)
dp = p_grid[2] - p_grid[1]
prior = dunif(p_grid, 0, 1)
likelihood = dbinom(0, size=8, prob=p_grid)
unnorm_posterior = prior * likelihood
grid_posterior = unnorm_posterior / sum(unnorm_posterior)

quad_posterior = dnorm(p_grid, mean=mean_est, sd=sd_est)

ggplot() + geom_line(aes(x=p_grid, y=grid_posterior, color="Grid posterior")) +
		   geom_line(aes(x=p_grid, y=quad_posterior*dp, color="Quadratic posterior")) +
		   xlab("Prob. successful attack") + ylab("Probability") + theme_classic()

# ggsave("compare_posteriors.pdf", width=5, height=3)
```


```{r}
## Quadratic approximation: Approach 2

posterior_nh = function(p, data){
	log_prior = dunif(p, 0, 1, log=TRUE)
	log_likelihood = dbinom(data$Y, data$Y + data$F, p, log=TRUE)
	return(-1*(log_prior + log_likelihood))
}

# Use optim t
res = optim(0.5, posterior_nh, data=list(Y=6, F=2), 
			method="L-BFGS-B", lower=1e-6, upper=1 - 1e-6,
			hessian=TRUE)

# Extract the mode estimate
mean_est1 = res$par

# The inverse of the hessian is the standard error
sd_est1 = sqrt(1 / res$hessian)
```

```{r}
## Red-tailed hawk inference

### Grid approximation

# 1. Define your grid
p_grid = seq(0, 1, len=100)

# 2. Define your prior
prior = dunif(p_grid, 0, 1)

# 3. Define your likelihood
likelihood = dbinom(0, size=8, prob=p_grid)

# 4. Unnormalized posterior
unnorm_posterior_red = likelihood * prior

# Normalize posterior
posterior_red = unnorm_posterior_red / sum(unnorm_posterior_red)

ggplot() + geom_line(aes(x=p_grid, y=posterior_red)) + theme_classic()

### Quadratic approximation

# You can't get it to converge because the MAP is on the boundary
# There is no curvature!
# An inherent problem with the quap approach

redtailed = quap(
		alist(
				Y ~ dbinom(Y + F, p),
				p ~ dunif(0, 1)
		),
		data=list(Y=0, F=8))
```